ggplot(data = water, mapping = aes(x = Precip, y = residuals)) +
geom_point() +
theme(aspect.ratio = 1)
# Boxplot
water_boxplot <- ggplot(data = water) +
geom_boxplot(mapping = aes(y = residuals)) +
theme(aspect.ratio = 1)
water_boxplot
# Histogram
water_hist <- ggplot(data = water) +
geom_histogram(mapping = aes(x = residuals, y = ..density..),
binwidth = 6000) +
stat_function(fun = dnorm,
color = "red",
size = 2,
args = list(mean = mean(water$residuals),
sd = sd(water$residuals))) +
theme(aspect.ratio = 1)
water_hist
# Normal Probability Plot
water_qq <- autoplot(water.lm, which = 2, ncol = 1, nrow = 1) +
theme(aspect.ratio = 1)
water_qq
# Shapiro-Wilk Test
shapiro.test(water$residuals)
# Residuals vs. Fitted Values Plot
autoplot(water.lm, which = 1, ncol = 1, nrow = 1) +
theme(aspect.ratio = 1)
# Brown-Forsythe Test
grp <- as.factor(c(rep("lower", floor(dim(water)[1] / 2)),
rep("upper", ceiling(dim(water)[1] / 2))))
leveneTest(unlist(water[order(water$Precip), "residuals"]) ~ grp,
center = median)
# Scatterplot
water.base.plot
# Boxplot
water_boxplot
# Histogram
water_hist
# Normal Probability Plot
water_qq
###### Cook's Distance
# get Cook's distance values for all observations
water$cooksd <- cooks.distance(water.lm)
# plot Cook's distance against the observation number
ggplot(data = water) +
geom_point(mapping = aes(x = as.numeric(rownames(water)),
y = cooksd)) +
ylab("Cook's Distance") +
xlab("Observation Number") +
geom_hline(mapping = aes(yintercept = 4 / length(cooksd)),
color = "red",
linetype = "dashed") +
theme(aspect.ratio = 1)
# print a list of potential outliers according to Cook's distance
water %>%
mutate(rowNum = row.names(water)) %>%  # save original row numbers
filter(cooksd > 4 / length(cooksd)) %>%  # select potential outliers
arrange(desc(cooksd))  # order from largest Cook's distance to smallest
###### DFBETAS
# calculate the DFBETAS for Precip
water$dfbetas_Precip <- as.vector(dfbetas(water.lm)[, 2])
# plot the DFBETAS against the observation number
ggplot(data = water) +
geom_point(mapping = aes(x = as.numeric(rownames(water)),
y = abs(dfbetas_Precip))) +
ylab("Absolute Value of DFBETAS for Precip") +
xlab("Observation Number") +
# for n > 30
geom_hline(mapping = aes(yintercept = 2 / sqrt(length(dfbetas_Precip))),
color = "red",
linetype = "dashed") +
theme(aspect.ratio = 1)
# print a list of potential influential points according to DFBETAS
# for n > 30
water %>%
mutate(rowNum = row.names(water)) %>%  # save original row numbers
filter(abs(dfbetas_Precip) > 2 /
sqrt(length(rownames(water)))) %>%  # select potential influential pts
arrange(desc(abs(dfbetas_Precip)))  # order from largest DFBETAS to smallest
###### DFFITS
# calculate the DFFITS
water$dffits <- dffits(water.lm)
# plot the DFFITS against the observation number
ggplot(data = water) +
geom_point(mapping = aes(x = as.numeric(rownames(water)),
y = abs(dffits))) +
ylab("Absolute Value of DFFITS for Y") +
xlab("Observation Number") +
# for n > 30
geom_hline(mapping = aes(yintercept = 2 * sqrt(length(water.lm$coefficients) /
length(dffits))),
color = "red",
linetype = "dashed") +
theme(aspect.ratio = 1)
# print a list of potential influential points according to DFFITS
# for n > 30
water %>%
mutate(rowNum = row.names(water)) %>%  # save original row numbers
# select potential influential pts
filter(abs(dffits) > 2 * sqrt(length(water.lm$coefficients) /
length(dffits))) %>%
arrange(desc(abs(dffits)))  # order from largest DFFITS to smallest
confint(water.lm, level = 0.95, parm = "Precip")
summary(water.lm)
predict(water.lm,
newdata = data.frame(Precip = 30),
interval = "confidence",
level = 0.95)
# Sequence of Precip values that we are interested in using to predict Runoff
precip_values <- seq(min(water$Precip), max(water$Precip), by = 0.05)
# 95% confidence intervals of Runoff across those values of Precip
conf_int_mean <- predict(water.lm,
newdata = data.frame(Precip = precip_values),
interval = "confidence",
level = 0.95)
# Store results in a data frame for plotting
preds <- data.frame("precip_values" = precip_values, conf_int_mean)
# Plot the predictions
water.base.plot +
geom_line(data = preds, mapping = aes(x = precip_values, y = fit),
color = "blue", size = 1.5) +
geom_line(data = preds, mapping = aes(x = precip_values, y = lwr),
color = "#d95f02", size = 1.5) +
geom_line(data = preds, mapping = aes(x = precip_values, y = upr),
color = "#d95f02", size = 1.5) +
scale_y_continuous(limits = c(30000, 160000))  # lower y-axis to see entire ln
predict(water.lm,
newdata = data.frame(Precip = 30),
interval = "prediction",
level = 0.95)
# Sequence of Precip values that we are interested in using to predict Runoff
precip_values <- seq(min(water$Precip), max(water$Precip), by = 0.05)
# 95% confidence intervals of Runoff across those values of Precip
pred_int_mean <- predict(water.lm,
newdata = data.frame(Precip = precip_values),
interval = "prediction",
level = 0.95)
# Store results in a data frame for plotting
preds <- data.frame("precip_values" = precip_values, pred_int_mean)
# Plot the predictions
water.base.plot +
geom_line(data = preds, mapping = aes(x = precip_values, y = fit),
color = "blue", size = 1.5) +
geom_line(data = preds, mapping = aes(x = precip_values, y = lwr),
color = "#1b9e77", size = 1.5) +
geom_line(data = preds, mapping = aes(x = precip_values, y = upr),
color = "#1b9e77", size = 1.5) +
scale_y_continuous(limits = c(10000, 175000),  # lower y-axis to see entire line
breaks = seq(10000, 175000, by = 15000))
anova <- aov(water.lm)  # get ANOVA components
water_anova <- summary(anova)[[1]]  # save data in a usable form
water_anova
mse <- water_anova["Residuals", "Sum Sq"] / water_anova["Residuals", "Df"]
mse
rmse <- sqrt(mse)
rmse
mae <- sum(abs(water$Runoff - water$fittedRunoff)) / (length(water$Runoff) - 2)
mae
summary(water.lm)
4+2*3
(.7*(9927.12)+.3*(9885.35))/(.7*(9965.22)+.3*(9927.12))
(.5*(9927.12 + 9885.35))/(.2*10000 + .8*9965.22)
((.4*9965.22 + 6*9927.12) - (.3*9885.35 + .7*9839.55))/(.2*10000 + .8*9965.22)
((.4*9965.22 + .6*9927.12) - (.3*9885.35 + .7*9839.55))/(.2*10000 + .8*9965.22)
(9885.35/9927.12)^.5
x <- (9965.22/10000)^.2
x1 <- (9927.12/9965.22)
x2 <- (9885.35/9927.12)^.5
x*x1*x2
1 - x*x1*x2
937373/942944
938359/942944
938359/943671
# load any necessary packages here
library(tidyverse)
library(ggfortify)  # plot lm objects using ggplot instead of base R
library(car)  # Brown-Forsythe Test and Box-Cox transformation
stop <- read_table("StoppingDistance.txt")
summary(stop)
stop_base_plot <- ggplot(data = stop) +
geom_point(mapping = aes(x = Speed, y = Distance)) +
ylab("Distance to Stop (feet)") +
xlab("Speed (MPH)") +
theme(aspect.ratio = 1)
stop_base_plot
stop_base_plot +
scale_y_continuous(limits = c(-10, 150)) +
geom_smooth(mapping = aes(x = Speed, y = Distance),
method = "lm",
se = FALSE)
mod <- lm(Distance ~ Speed, data = stop)
summary(mod)
stop$residuals <- mod$residuals
stop$fittedDistance <- mod$fitted.values
# Scatterplot
stop_base_plot
# Residuals vs. Fitted Values Plot
autoplot(mod, which = 1, ncol = 1, nrow = 1) +
theme(aspect.ratio = 1)
# Residuals vs. Predictor Plot
ggplot(data = stop) +
geom_point(mapping = aes(x = Speed, y = residuals)) +
theme(aspect.ratio = 1)
# Boxplot
ggplot(data = stop) +
geom_boxplot(mapping = aes(y = residuals)) +
theme(aspect.ratio = 1)
# Histogram
ggplot(data = stop) +
geom_histogram(mapping = aes(x = residuals, y = ..density..),
binwidth = 6) +
stat_function(fun = dnorm,
color = "red",
size = 2,
args = list(mean = mean(stop$residuals),
sd = sd(stop$residuals))) +
theme(aspect.ratio = 1)
# Normal Probability Plot
autoplot(mod, which = 2, ncol = 1, nrow = 1) +
theme(aspect.ratio = 1)
# Shapiro-Wilk Test
shapiro.test(stop$residuals)
# Residuals vs. Fitted Values Plot
autoplot(mod, which = 1, ncol = 1, nrow = 1) +
theme(aspect.ratio = 1)
# Brown-Forsythe Test
grp <- as.factor(c(rep("lower", floor(dim(stop)[1] / 2)),
rep("upper", ceiling(dim(stop)[1] / 2))))
leveneTest(unlist(stop[order(stop$Speed), "residuals"]) ~ grp,
center = median)
# Scatterplot
stop_base_plot
# Boxplot
ggplot(data = stop) +
geom_boxplot(mapping = aes(y = residuals)) +
theme(aspect.ratio = 1)
# Histogram
ggplot(data = stop) +
geom_histogram(mapping = aes(x = residuals, y = ..density..),
binwidth = 6) +
stat_function(fun = dnorm,
color = "red",
size = 2,
args = list(mean = mean(stop$residuals),
sd = sd(stop$residuals))) +
theme(aspect.ratio = 1)
# Normal Probability Plot
autoplot(mod, which = 2, ncol = 1, nrow = 1) +
theme(aspect.ratio = 1)
############## Cook's Distance
# get Cook's distance values for all observations
stop$cooksd <- cooks.distance(mod)
# plot Cook's distance against the observation number
ggplot(data = stop) +
geom_point(mapping = aes(x = as.numeric(rownames(stop)),
y = cooksd)) +
ylab("Cook's Distance") +
xlab("Observation Number") +
geom_hline(mapping = aes(yintercept = 4 / length(cooksd)),
color = "red",
linetype = "dashed") +
theme(aspect.ratio = 1)
# print a list of potential outliers according to Cook's distance
stop %>%
mutate(rowNum = row.names(stop)) %>%  # save original row numbers
filter(cooksd > 4 / length(cooksd)) %>%  # select potential outliers
arrange(desc(cooksd))  # order from largest Cook's distance to smallest
############## DFBETAS
# calculate the DFBETAS for Speed
stop$dfbetas_Speed <- as.vector(dfbetas(mod)[, 2])
# plot the DFBETAS against the observation number
ggplot(data = stop) +
geom_point(mapping = aes(x = as.numeric(rownames(stop)),
y = abs(dfbetas_Speed))) +
ylab("Absolute Value of DFBETAS for Speed") +
xlab("Observation Number") +
# for n > 30
geom_hline(mapping = aes(yintercept = 2 / sqrt(length(dfbetas_Speed))),
color = "red",
linetype = "dashed") +
theme(aspect.ratio = 1)
# print a list of potential influential points according to DFBETAS
# for n > 30
stop %>%
mutate(rowNum = row.names(stop)) %>%  # save original row numbers
filter(abs(dfbetas_Speed) > 2 /
sqrt(length(rownames(stop)))) %>%  # select potential influential pts
arrange(desc(abs(dfbetas_Speed)))  # order from largest DFBETAS to smallest
############## DFFITS
# calculate the DFFITS
stop$dffits <- dffits(mod)
# plot the DFFITS against the observation number
ggplot(data = stop) +
geom_point(mapping = aes(x = as.numeric(rownames(stop)),
y = abs(dffits))) +
ylab("Absolute Value of DFFITS for Y") +
xlab("Observation Number") +
# for n > 30
geom_hline(mapping = aes(yintercept = 2 * sqrt(length(mod$coefficients) /
length(dffits))),
color = "red",
linetype = "dashed") +
theme(aspect.ratio = 1)
# print a list of potential influential points according to DFFITS
# for n > 30
stop %>%
mutate(rowNum = row.names(stop)) %>%  # save original row numbers
# select potential influential pts
filter(abs(dffits) > 2 * sqrt(length(mod$coefficients) /
length(dffits))) %>%
arrange(desc(abs(dffits)))  # order from largest DFFITS to smallest
bc <- boxCox(stop$Distance ~ stop$Speed)
bc$x[which.max(bc$y)]  # "best" lambda value
stop$Distance_trans <- sqrt(stop$Distance)
mod_trans <- lm(Distance_trans ~ Speed, data = stop)
summary(mod_trans)
stop$residuals_trans <- mod_trans$residuals
stop$fittedDistance_trans <- mod_trans$fitted.values
# Scatterplot
stop_trans_base_plot <- ggplot(data = stop) +
geom_point(mapping = aes(x = Speed, y = Distance_trans)) +
ylab("Distance to Stop (sqrt(feet))") +
xlab("Speed (MPH)") +
theme(aspect.ratio = 1)
stop_trans_base_plot
# Residuals vs. Fitted Values Plot
autoplot(mod_trans, which = 1, ncol = 1, nrow = 1) +
theme(aspect.ratio = 1)
# Residuals vs. Predictor Plot
ggplot(data = stop) +
geom_point(mapping = aes(x = Speed, y = residuals_trans)) +
theme(aspect.ratio = 1)
# Boxplot
ggplot(data = stop) +
geom_boxplot(mapping = aes(y = residuals_trans)) +
theme(aspect.ratio = 1)
# Histogram
ggplot(data = stop) +
geom_histogram(mapping = aes(x = residuals_trans, y = ..density..),
binwidth = 0.5) +
stat_function(fun = dnorm,
color = "red",
size = 2,
args = list(mean = mean(stop$residuals_trans),
sd = sd(stop$residuals_trans))) +
theme(aspect.ratio = 1)
# Normal Probability Plot
autoplot(mod_trans, which = 2, ncol = 1, nrow = 1) +
theme(aspect.ratio = 1)
# Shapiro-Wilk Test
shapiro.test(stop$residuals_trans)
# Residuals vs. Fitted Values Plot
autoplot(mod_trans, which = 1, ncol = 1, nrow = 1) +
theme(aspect.ratio = 1)
# Brown-Forsythe Test
grp <- as.factor(c(rep("lower", floor(dim(stop)[1] / 2)),
rep("upper", ceiling(dim(stop)[1] / 2))))
leveneTest(unlist(stop[order(stop$Speed), "residuals_trans"]) ~ grp, center = median)
# Scatterplot
stop_trans_base_plot
# Boxplot
ggplot(data = stop) +
geom_boxplot(mapping = aes(y = residuals_trans)) +
theme(aspect.ratio = 1)
# Histogram
ggplot(data = stop) +
geom_histogram(mapping = aes(x = residuals_trans, y = ..density..),
binwidth = 0.5) +
stat_function(fun = dnorm,
color = "red",
size = 2,
args = list(mean = mean(stop$residuals_trans),
sd = sd(stop$residuals_trans))) +
theme(aspect.ratio = 1)
# Normal Probability Plot
autoplot(mod_trans, which = 2, ncol = 1, nrow = 1) +
theme(aspect.ratio = 1)
############## Cook's Distance
# get Cook's distance values for all observations
stop$cooksd_trans <- cooks.distance(mod_trans)
# plot Cook's distance against the observation number
ggplot(data = stop) +
geom_point(mapping = aes(x = as.numeric(rownames(stop)),
y = cooksd_trans)) +
ylab("Cook's Distance") +
xlab("Observation Number") +
geom_hline(mapping = aes(yintercept = 4 / length(cooksd_trans)),
color = "red",
linetype = "dashed") +
theme(aspect.ratio = 1)
# print a list of potential outliers according to Cook's distance
stop %>%
mutate(rowNum = row.names(stop)) %>%  # save original row numbers
filter(cooksd_trans > 4 / length(cooksd_trans)) %>%  # select potential outliers
arrange(desc(cooksd_trans))  # order from largest Cook's distance to smallest
############## DFBETAS
# calculate the DFBETAS for Speed
stop$dfbetas_trans_Speed <- as.vector(dfbetas(mod_trans)[, 2])
# plot the DFBETAS against the observation number
ggplot(data = stop) +
geom_point(mapping = aes(x = as.numeric(rownames(stop)),
y = abs(dfbetas_trans_Speed))) +
ylab("Absolute Value of DFBETAS for Speed") +
xlab("Observation Number") +
# for n > 30
geom_hline(mapping = aes(yintercept = 2 / sqrt(length(dfbetas_trans_Speed))),
color = "red",
linetype = "dashed") +
theme(aspect.ratio = 1)
# print a list of potential influential points according to DFBETAS
# for n > 30
stop %>%
mutate(rowNum = row.names(stop)) %>%  # save original row numbers
filter(abs(dfbetas_trans_Speed) > 2 /
sqrt(length(rownames(stop)))) %>%  # select potential influential pts
arrange(desc(abs(dfbetas_trans_Speed)))  # order from largest DFBETAS to smallest
############## DFFITS
# calculate the DFFITS
stop$dffits_trans <- dffits(mod_trans)
# plot the DFFITS against the observation number
ggplot(data = stop) +
geom_point(mapping = aes(x = as.numeric(rownames(stop)),
y = abs(dffits_trans))) +
ylab("Absolute Value of DFFITS for Y") +
xlab("Observation Number") +
# for n > 30
geom_hline(mapping = aes(yintercept = 2 * sqrt(length(mod_trans$coefficients) /
length(dffits_trans))),
color = "red",
linetype = "dashed") +
theme(aspect.ratio = 1)
# print a list of potential influential points according to DFFITS
# for n > 30
stop %>%
mutate(rowNum = row.names(stop)) %>%  # save original row numbers
# select potential influential pts
filter(abs(dffits_trans) > 2 * sqrt(length(mod_trans$coefficients) /
length(dffits_trans))) %>%
arrange(desc(abs(dffits)))  # order from largest DFFITS to smallest
# Sequence of Speed values that we are interested in using to predict Distance
Speed_values <- seq(min(stop$Speed), max(stop$Speed), length = 100)
# Predictions of **sqrt(Distance)** across those values of Speed
sqrt_Distance_preds <- predict(mod_trans,
newdata = data.frame(Speed = Speed_values))
# Predictions of **Distance** (back-transformed) across those value of Speed
Distance_preds <- sqrt_Distance_preds^2  # use ^2 to "undo" the sqrt transform
# Store results in a data frame for plotting
preds <- data.frame("Speed_values" = Speed_values,
"Distance_preds" = Distance_preds)
# Plot the predictions on the original scale (to get a curved line)
stop_base_plot +
geom_line(data = preds,
aes(x = Speed_values, y = Distance_preds),
size = 1.5, color ="blue")
940202 - 938359
(940202 - 938359)/943435
938359/943435
941916/943435 + 940202/943435 + 938359/943435
1- ((936482/938359)*(934572/936482)^.6)
1- ((936482/938265)*(934572/936482)^.6)
1- ((936482/938265)*((.4*936482 + .6*934572)/936482))
setwd("~/Documents/STAT348/AmazonEmployeeAccess")
library(tidymodels)
amazon_train <- vroom("train.csv")
amazon_train$ACTION <- as.factor(amazon_train$ACTION)
amazon_test <-vroom("test.csv")
view(amazon_test)
amazon_test <-vroom("test.csv")
library(tidymodels)
library(tidyverse)
library(tidymodels)
library(vroom)
library(patchwork)
library(poissonreg)
library(parsnip)
library(glmnet)
library(rpart)
library(ranger)
library(stacks)
library(dbarts)
library(embed)
amazon_train <- vroom("train.csv")
amazon_train$ACTION <- as.factor(amazon_train$ACTION)
amazon_test <-vroom("test.csv")
view(amazon_test)
n <- length(amazon_test)
length(amazon_test)
count(amazon_test)
n <- count(amazon_test)
my_recipe <- recipe(ACTION ~ ., data = amazon_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = .01) %>%
step_dummy(all_nominal_predictors())
prep <- prep(my_recipe)
bake <- bake(prep, new_data = amazon_train)
prep
my_recipe <- recipe(ACTION ~ ., data = amazon_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_normalize(all_nominal_predictors())
prep <- prep(my_recipe)
bake <- bake(prep, new_data = amazon_train)
knn_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(knn_model)
knn_model <- nearest_neighbor(neighbors = sqrt(n)) %>%
set_mode("classification") %>%
set_engine("kknn")
knn_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(knn_model)
predict(knn_wf, new_data = amazon_test)
